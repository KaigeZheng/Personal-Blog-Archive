<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="å¤§æ¨¡å‹å­¦ä¹ ç¬”è®°ï¼ˆä¸€ï¼‰"><title>ä»Transformerå¼€å§‹æ¢ç´¢BERT</title><link rel=canonical href=https://kaigezheng.github.io/p/llm1/><link rel=stylesheet href=/scss/style.min.f0b427a7e322d7ca4439d64cb0fb1eab709bbe5dc0a5bf10c9071e75f49fced4.css><meta property='og:title' content="ä»Transformerå¼€å§‹æ¢ç´¢BERT"><meta property='og:description' content="å¤§æ¨¡å‹å­¦ä¹ ç¬”è®°ï¼ˆä¸€ï¼‰"><meta property='og:url' content='https://kaigezheng.github.io/p/llm1/'><meta property='og:site_name' content="Kambri's Blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='æ–‡æ¡£'><meta property='article:tag' content='AI Infra'><meta property='article:published_time' content='2025-06-02T22:55:00+08:00'><meta property='article:modified_time' content='2025-06-02T22:55:00+08:00'><meta property='og:image' content='https://kaigezheng.github.io/p/llm1/img/cover.png'><meta name=twitter:title content="ä»Transformerå¼€å§‹æ¢ç´¢BERT"><meta name=twitter:description content="å¤§æ¨¡å‹å­¦ä¹ ç¬”è®°ï¼ˆä¸€ï¼‰"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://kaigezheng.github.io/p/llm1/img/cover.png'><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label=åˆ‡æ¢èœå•>
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu_98fe1fefb25c1393.png width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>ğŸ« </span></figure><div class=site-meta><h1 class=site-name><a href=/>Kambri's Blog</a></h1><h2 class=site-description>ä½ å¥½ï¼è¿™é‡Œæ˜¯Kambriçš„æŠ€æœ¯&ç”Ÿæ´»åšå®¢ï¼Œæˆ‘å°†åœ¨è¿™é‡Œåˆ†äº«æŠ€æœ¯ç»éªŒå’Œè®°å½•ç”Ÿæ´»ã€‚</h2></div></header><ol class=menu-social><li><a href=https://github.com/KaigeZheng target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=mailto:kambrikg@gmail.com target=_blank title=é‚®ç®±(kambrikg@gmail.com) rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-mail"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M3 7a2 2 0 012-2h14a2 2 0 012 2v10a2 2 0 01-2 2H5a2 2 0 01-2-2V7z"/><path d="M3 7l9 6 9-6"/></svg></a></li><li><a href=https://kaigezheng.github.io/index.xml target=_blank title=RSS rel=me><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-rss"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M5 19m-1 0a1 1 0 102 0 1 1 0 10-2 0"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>ä¸»é¡µ|Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>å½’æ¡£|Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>æœç´¢|Search</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>å‹é“¾|Links</span></a></li><li><a href=/devlog/><svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tabler icons-tabler-outline icon-tabler-logs"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 12h.01"/><path d="M4 6h.01"/><path d="M4 18h.01"/><path d="M8 18h2"/><path d="M8 12h2"/><path d="M8 6h2"/><path d="M14 6h6"/><path d="M14 12h6"/><path d="M14 18h6"/></svg>
<span>æ—¥å¿—|Logs</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>æš—è‰²æ¨¡å¼</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">ç›®å½•</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#bert-architecture>BERT Architecture</a><ol><li><a href=#total-summary>Total Summary</a></li><li><a href=#a-simple-demo>A Simple Demo</a><ol><li><a href=#modelconfig>model.config</a></li><li><a href=#rules-on-tokenizer>Rules on Tokenizer</a></li><li><a href=#parameter>Parameter</a></li><li><a href=#output>Output</a></li></ol></li><li><a href=#embedding>Embedding</a></li><li><a href=#self-attention>Self-Attention</a></li><li><a href=#add--norm>Add & Norm</a></li><li><a href=#pooler>Pooler</a></li></ol></li><li><a href=#masked-language-model>Masked Language Model</a><ol><li><a href=#cls-layer>CLS Layer</a></li><li><a href=#masking>Masking</a></li><li><a href=#computing-process>Computing Process</a></li><li><a href=#loss--translate>Loss & Translate</a></li></ol></li><li><a href=#fine-tuning-task-text-classification>Fine-Tuning Task (Text Classification)</a><ol><li><a href=#data>Data</a><ol><li><a href=#data-load---emotions>Data Load - emotions</a></li><li><a href=#data-visualization-analysis>Data Visualization Analysis</a></li><li><a href=#text2tokens>Text2Tokens</a></li></ol></li><li><a href=#model-fine-tuning>Model Fine-Tuning</a><ol><li><a href=#load-model>Load Model</a></li><li><a href=#transformers-trainer>Transformers Trainer</a></li><li><a href=#inference>Inference</a></li><li><a href=#push-into-huggingface>Push into Huggingface</a></li></ol></li></ol></li><li><a href=#reference>Reference</a></li></ol></nav></div></section></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/p/llm1/><img src=/p/llm1/img/cover_hu_8c64f49e37c40d94.png srcset="/p/llm1/img/cover_hu_8c64f49e37c40d94.png 800w, /p/llm1/img/cover_hu_e49eab28483df9c6.png 1600w" width=800 height=291 loading=lazy alt="Featured image of post ä»Transformerå¼€å§‹æ¢ç´¢BERT"></a></div><div class=article-details><header class=article-category><a href=/categories/%E6%96%87%E6%A1%A3/ style=background-color:#2a9d8f;color:#fff>æ–‡æ¡£
</a><a href=/categories/ai-infra/ style=background-color:#7b79e6;color:#fff>AI Infra</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/llm1/>ä»Transformerå¼€å§‹æ¢ç´¢BERT</a></h2><h3 class=article-subtitle>å¤§æ¨¡å‹å­¦ä¹ ç¬”è®°ï¼ˆä¸€ï¼‰</h3></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Jun 02, 2025</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>é˜…è¯»æ—¶é•¿: 15 åˆ†é’Ÿ</time></div></footer></div></header><section class=article-content><h2 id=bert-architecture>BERT Architecture</h2><h3 id=total-summary>Total Summary</h3><p>BERTçš„æ¨¡å‹æ¶æ„å®Œå…¨åŸºäºTransformeræ¶æ„çš„ç¼–ç å™¨ï¼ˆEncoderï¼‰å †å ï¼ˆåŸæ–‡ä½¿ç”¨12å±‚æˆ–24å±‚Transformer Layerï¼‰ï¼Œæ¯ä¸ªEncoderåŒ…æ‹¬<strong>å¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶</strong>ï¼ˆMHAï¼ŒMulti-Head Self-Attentionï¼Œæ”¯æŒåŒå‘ä¸Šä¸‹æ–‡ç†è§£ï¼‰ã€<strong>å‰é¦ˆç¥ç»ç½‘ç»œ</strong>ï¼ˆFFNï¼ŒFeed-Forward Networkï¼Œå¯¹æ³¨æ„åŠ›è¾“å‡ºè¿›è¡Œéçº¿æ€§å˜æ¢ï¼‰ï¼Œ<strong>å‚å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–</strong>ï¼ˆAdd & Normï¼Œæå‡è®­ç»ƒç¨³å®šæ€§ï¼‰ã€‚</p><figure><img src=/p/llm1/img/1.png width='400px"'><figcaption><h4>Transformer Model Architecture</h4></figcaption></figure><h3 id=a-simple-demo>A Simple Demo</h3><p>è¿™é‡Œä»¥ä¸€ä¸ªHuggingfaceå‘å¸ƒçš„ç”¨äºè‹±æ–‡å¥å­æƒ…æ„ŸäºŒåˆ†ç±»çš„è’¸é¦BERT<a class=link href=https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english target=_blank rel=noopener>DistilBERT (distilbert-base-uncased-finetuned-sst-2-english) 66M</a>ä¸ºä¾‹ï¼Œä½¿ç”¨transformersåº“å®ç°åŠ è½½å¹¶æ¨ç†ã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>huggingface-cli download distilbert/distilbert-base-uncased-finetuned-sst-2-english --local-dir distilbert-base-uncased-finetuned-sst-2-english
</span></span></code></pre></td></tr></table></div></div><p>ä¸‹è½½æ¨¡å‹åï¼Œå³å¯é€šè¿‡<code>AutoTokenizer</code>å’Œ<code>AutoModelForSequenceClassification</code>å¯¼å…¥æ¨¡å‹ã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn.functional</span> <span class=k>as</span> <span class=nn>F</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoTokenizer</span><span class=p>,</span> <span class=n>AutoModelForSequenceClassification</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># åŠ è½½tokenizerå’Œmodel</span>
</span></span><span class=line><span class=cl><span class=n>model_name</span> <span class=o>=</span> <span class=s1>&#39;/path/to/bert-model&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForSequenceClassification</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># sentence -&gt; tokens</span>
</span></span><span class=line><span class=cl><span class=n>test_sentences</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;today is not that bad&#39;</span><span class=p>,</span> <span class=s1>&#39;today is so bad&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>batch_input</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=p>(</span><span class=n>test_sentences</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>truncation</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s1>&#39;pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># inference</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=n>batch_input</span><span class=p>)</span>              <span class=c1># è§£åŒ…tokens -&gt; inference result</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;outputs&#34;</span><span class=p>,</span> <span class=n>outputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scores</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>outputs</span><span class=o>.</span><span class=n>logits</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>   <span class=c1># å¯¹logits(é¢„æµ‹åˆ†æ•°)å¯¹æ¯ä¸€è¡Œï¼ˆç±»åˆ«ï¼‰è¿›è¡Œsoftmax</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;scores&#34;</span><span class=p>,</span> <span class=n>scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>labels</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>scores</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>        <span class=c1># æ²¿ç±»åˆ«ç»´åº¦è·å–æœ€å¤§å€¼ç´¢å¼•</span>
</span></span><span class=line><span class=cl>    <span class=n>labels</span> <span class=o>=</span> <span class=p>[</span><span class=n>model</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>id2label</span><span class=p>[</span><span class=nb>id</span><span class=o>.</span><span class=n>item</span><span class=p>()]</span> <span class=k>for</span> <span class=nb>id</span> <span class=ow>in</span> <span class=n>labels</span><span class=p>]</span>  <span class=c1># 0-&gt;LABEL_0, 1-&gt;LABEL_1</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;labels&#34;</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>å³å¯å¾—åˆ°ä»¥ä¸‹æ¨ç†ç»“æœï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>outputs SequenceClassifierOutput<span class=o>(</span><span class=nv>loss</span><span class=o>=</span>None, <span class=nv>logits</span><span class=o>=</span>tensor<span class=o>([[</span>-3.4620,  3.6118<span class=o>]</span>,
</span></span><span class=line><span class=cl>        <span class=o>[</span> 4.7508, -3.7899<span class=o>]])</span>, <span class=nv>hidden_states</span><span class=o>=</span>None, <span class=nv>attentions</span><span class=o>=</span>None<span class=o>)</span>
</span></span><span class=line><span class=cl>scores tensor<span class=o>([[</span>8.4632e-04, 9.9915e-01<span class=o>]</span>,
</span></span><span class=line><span class=cl>        <span class=o>[</span>9.9980e-01, 1.9531e-04<span class=o>]])</span>
</span></span><span class=line><span class=cl>labels <span class=o>[</span><span class=s1>&#39;POSITIVE&#39;</span>, <span class=s1>&#39;NEGATIVE&#39;</span><span class=o>]</span>
</span></span></code></pre></td></tr></table></div></div><p>å…³äº<code>with torch.no_grad()</code>å’Œ<code>param.requires_grad=False</code>çš„åŒºåˆ«ï¼š</p><ul><li><p><code>with torch.no_grad()</code>é€‚ç”¨äºevalé˜¶æ®µï¼Œå®šä¹‰äº†ä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œéšå¼ä¸è¿›è¡Œæ¢¯åº¦æ›´æ–°ï¼Œä¸ä¼šæ”¹å˜requires_grad</p></li><li><p><code>param.requires_grad=False</code>æ˜¾å¼åœ°frozenæ‰ä¸€äº›layerçš„æ¢¯åº¦æ›´æ–°</p></li></ul><p>æ¥ä¸‹æ¥éœ€è¦å¯¹ä¸€äº›ç»†èŠ‚è¿›è¡Œè¡¥å……ã€‚</p><h4 id=modelconfig>model.config</h4><p><code>model.config</code>ç”¨äºå­˜å‚¨æ¨¡å‹æ¶æ„å’Œè®­ç»ƒé…ç½®ã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>DistilBertConfig {
</span></span><span class=line><span class=cl>  &#34;activation&#34;: &#34;gelu&#34;,
</span></span><span class=line><span class=cl>  &#34;architectures&#34;: [
</span></span><span class=line><span class=cl>    &#34;DistilBertForSequenceClassification&#34;
</span></span><span class=line><span class=cl>  ],
</span></span><span class=line><span class=cl>  &#34;attention_dropout&#34;: 0.1,
</span></span><span class=line><span class=cl>  &#34;dim&#34;: 768,
</span></span><span class=line><span class=cl>  &#34;dropout&#34;: 0.1,
</span></span><span class=line><span class=cl>  &#34;finetuning_task&#34;: &#34;sst-2&#34;,
</span></span><span class=line><span class=cl>  &#34;hidden_dim&#34;: 3072,
</span></span><span class=line><span class=cl>  &#34;id2label&#34;: {
</span></span><span class=line><span class=cl>    &#34;0&#34;: &#34;NEGATIVE&#34;,
</span></span><span class=line><span class=cl>    &#34;1&#34;: &#34;POSITIVE&#34;
</span></span><span class=line><span class=cl>  },
</span></span><span class=line><span class=cl>  &#34;initializer_range&#34;: 0.02,
</span></span><span class=line><span class=cl>  &#34;label2id&#34;: {
</span></span><span class=line><span class=cl>    &#34;NEGATIVE&#34;: 0,
</span></span><span class=line><span class=cl>    &#34;POSITIVE&#34;: 1
</span></span><span class=line><span class=cl>  },
</span></span><span class=line><span class=cl>  &#34;max_position_embeddings&#34;: 512,
</span></span><span class=line><span class=cl>  &#34;model_type&#34;: &#34;distilbert&#34;,
</span></span><span class=line><span class=cl>  &#34;n_heads&#34;: 12,
</span></span><span class=line><span class=cl>  &#34;n_layers&#34;: 6,
</span></span><span class=line><span class=cl>  &#34;output_past&#34;: true,
</span></span><span class=line><span class=cl>  &#34;pad_token_id&#34;: 0,
</span></span><span class=line><span class=cl>  &#34;qa_dropout&#34;: 0.1,
</span></span><span class=line><span class=cl>  &#34;seq_classif_dropout&#34;: 0.2,
</span></span><span class=line><span class=cl>  &#34;sinusoidal_pos_embds&#34;: false,
</span></span><span class=line><span class=cl>  &#34;tie_weights_&#34;: true,
</span></span><span class=line><span class=cl>  &#34;torch_dtype&#34;: &#34;float32&#34;,
</span></span><span class=line><span class=cl>  &#34;transformers_version&#34;: &#34;4.52.3&#34;,
</span></span><span class=line><span class=cl>  &#34;vocab_size&#34;: 30522
</span></span><span class=line><span class=cl>}
</span></span></code></pre></td></tr></table></div></div><h4 id=rules-on-tokenizer>Rules on Tokenizer</h4><p>è°ƒç”¨<code>tokenizer</code>å³è°ƒç”¨<code>tokenizer.__call__</code>æˆ–<code>tokenizer.encoder</code>ï¼ˆä¸å®Œå…¨ç­‰ä»·ï¼Œencoderé»˜è®¤ä¸è¿”å›attention_maskï¼‰ï¼Œå°†è¿”å›å«æœ‰<code>input_ids</code>å’Œ<code>attention_mask</code>çš„è¾“å…¥å­—å…¸ï¼ˆ<code>inputs_ids</code>å’Œ<code>attention_mask</code>é•¿åº¦ä¸€è‡´ï¼‰ã€‚ï¼ˆå…·ä½“è¿”å›ä»€ä¹ˆè§†æ¨¡å‹å…·ä½“éœ€è¦è€Œå®šï¼‰</p><p><code>tokenizer.encoder</code>çš„è°ƒç”¨åˆ†ä¸ºä¸¤æ­¥ï¼Œå…ˆåˆ†è¯ï¼Œå†ç¼–ç ï¼Œæ‰€ä»¥ç­‰ä»·äºå…ˆè°ƒç”¨<code>tokenizer.tokenize</code>å†è°ƒç”¨<code>tokenizer.convert_tokens_to_ids</code>ã€‚</p><p>åœ¨å¥å­å¯¹ç¼–ç æ—¶ï¼Œä½¿ç”¨<code>tokenizer.encode_plus</code>ï¼Œåœ¨è¿”å›å­—å…¸ä¸­é™¤äº†<code>inputs_ids</code>å’Œ<code>attention_mask</code>ï¼Œè¿˜ä¼šè¿”å›<code>token_type_ids</code>$\in {0, 1}$ç”¨äºæ ‡è®°ç¬¬ä¸€å¥è¯å’Œç¬¬äºŒå¥è¯ã€‚åœ¨tokensä¸­ï¼Œä¼šç”¨[SEQ]åˆ†å‰²ã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># ç¼–ç </span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>tokenizer</span><span class=p>(</span><span class=n>test_sentences</span><span class=p>[</span><span class=mi>0</span><span class=p>]))</span>
</span></span><span class=line><span class=cl><span class=c1># tokenizer.encode = tokenizer.tokenize + tokenizer.convert_tokens_to_ids</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>test_sentences</span><span class=p>[</span><span class=mi>0</span><span class=p>],))</span>
</span></span><span class=line><span class=cl><span class=c1>## tokenize</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>tokenize</span><span class=p>(</span><span class=n>test_sentences</span><span class=p>[</span><span class=mi>0</span><span class=p>]))</span>
</span></span><span class=line><span class=cl><span class=c1>## convert_tokens_to_ids</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>convert_tokens_to_ids</span><span class=p>(</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>tokenize</span><span class=p>(</span><span class=n>test_sentences</span><span class=p>[</span><span class=mi>0</span><span class=p>])))</span>
</span></span><span class=line><span class=cl><span class=c1># è§£ç </span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>([</span><span class=mi>101</span><span class=p>,</span> <span class=mi>2651</span><span class=p>,</span> <span class=mi>2003</span><span class=p>,</span> <span class=mi>2025</span><span class=p>,</span> <span class=mi>2008</span><span class=p>,</span> <span class=mi>2919</span><span class=p>,</span> <span class=mi>102</span><span class=p>]))</span>
</span></span></code></pre></td></tr></table></div></div><p>å¯ä»¥å¾—åˆ°ä»¥ä¸‹ç»“æœï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># ç¼–ç </span>
</span></span><span class=line><span class=cl><span class=o>{</span><span class=s1>&#39;input_ids&#39;</span>: <span class=o>[</span>101, 2651, 2003, 2025, 2008, 2919, 102<span class=o>]</span>, <span class=s1>&#39;attention_mask&#39;</span>: <span class=o>[</span>1, 1, 1, 1, 1, 1, 1<span class=o>]}</span>
</span></span><span class=line><span class=cl><span class=o>[</span>101, 2651, 2003, 2025, 2008, 2919, 102<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=c1>## tokenize</span>
</span></span><span class=line><span class=cl><span class=o>[</span><span class=s1>&#39;today&#39;</span>, <span class=s1>&#39;is&#39;</span>, <span class=s1>&#39;not&#39;</span>, <span class=s1>&#39;that&#39;</span>, <span class=s1>&#39;bad&#39;</span><span class=o>]</span>
</span></span><span class=line><span class=cl><span class=c1>## convert_tokens_to_ids</span>
</span></span><span class=line><span class=cl><span class=o>[</span>2651, 2003, 2025, 2008, 2919<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=c1># è§£ç </span>
</span></span><span class=line><span class=cl><span class=o>[</span>CLS<span class=o>]</span> today is not that bad <span class=o>[</span>SEP<span class=o>]</span>
</span></span></code></pre></td></tr></table></div></div><p><code>tokenizer</code>æ˜¯æ ¹æ®<code>tokenizer.vocab</code>ä¸ºä¾æ®è¿›è¡Œç¼–ç çš„ï¼Œä»¥ä¸‹æ˜¯ç‰¹æ®Štokenè¡¨ï¼ˆå¯ä»¥é€šè¿‡<code>tokenizer.special_tokens_map</code>æˆ–ç›´æ¥<code>tokenizer</code>æŸ¥çœ‹ï¼‰ï¼Œtokenizerä¼šå°½é‡é¿å…å°†è¯åˆ†ä¸º[UNK]ï¼ˆå­˜åœ¨5828ä¸ª<code>##</code>å¼€å¤´çš„åç¼€å­è¯ï¼‰ã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>{&#39;unk_token&#39;: &#39;[UNK]&#39;,      # 100
</span></span><span class=line><span class=cl> &#39;sep_token&#39;: &#39;[SEP]&#39;,      # 102
</span></span><span class=line><span class=cl> &#39;pad_token&#39;: &#39;[PAD]&#39;,      # 0
</span></span><span class=line><span class=cl> &#39;cls_token&#39;: &#39;[CLS]&#39;,      # 101
</span></span><span class=line><span class=cl> &#39;mask_token&#39;: &#39;[MASK]&#39;     # 103}
</span></span></code></pre></td></tr></table></div></div><h4 id=parameter>Parameter</h4><p>è¿™é‡Œä»¥Googleå‘å¸ƒçš„<a class=link href="https://huggingface.co/google-bert/bert-base-uncased?text=Paris+is+the+%5BMASK%5D+of+France." target=_blank rel=noopener>google-bert/bert-base-uncased</a>ï¼ˆ12å±‚BertLayerï¼‰ä¸ºä¾‹ã€‚</p><p>é€šè¿‡<code>model</code>å¯ä»¥çœ‹åˆ°BERTçš„æ¶æ„å¦‚ä¸‹ï¼š</p><ul><li><p><strong>Embedding</strong>ç”±word embeddingsã€position embeddingså’Œtoken type embeddingä¸‰éƒ¨åˆ†ç»„æˆ</p></li><li><p><strong>Encoder</strong>ç”±12å±‚BertLayerç»„æˆï¼Œæ¯å±‚BertLayeréƒ½ç”±ä¸€æ¬¡Self Attentionå’Œä¸€æ¬¡FFNç»„æˆ</p></li><li><p><strong>Pooler</strong>å…¨è¿æ¥å±‚</p></li><li><p><strong>Output</strong>(optional)ä½œä¸ºä¸‹æ¸¸ä»»åŠ¡çš„è¾“å‡ºå±‚</p></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>BertModel(
</span></span><span class=line><span class=cl>  (embeddings): BertEmbeddings(
</span></span><span class=line><span class=cl>    (word_embeddings): Embedding(30522, 768, padding_idx=0)
</span></span><span class=line><span class=cl>    (position_embeddings): Embedding(512, 768)
</span></span><span class=line><span class=cl>    (token_type_embeddings): Embedding(2, 768)
</span></span><span class=line><span class=cl>    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
</span></span><span class=line><span class=cl>    (dropout): Dropout(p=0.1, inplace=False)
</span></span><span class=line><span class=cl>  )
</span></span><span class=line><span class=cl>  (encoder): BertEncoder(
</span></span><span class=line><span class=cl>    (layer): ModuleList(
</span></span><span class=line><span class=cl>      (0-11): 12 x BertLayer(
</span></span><span class=line><span class=cl>        (attention): BertAttention(
</span></span><span class=line><span class=cl>          (self): BertSdpaSelfAttention(
</span></span><span class=line><span class=cl>            (query): Linear(in_features=768, out_features=768, bias=True)
</span></span><span class=line><span class=cl>            (key): Linear(in_features=768, out_features=768, bias=True)
</span></span><span class=line><span class=cl>            (value): Linear(in_features=768, out_features=768, bias=True)
</span></span><span class=line><span class=cl>            (dropout): Dropout(p=0.1, inplace=False)
</span></span><span class=line><span class=cl>          )
</span></span><span class=line><span class=cl>          (output): BertSelfOutput(
</span></span><span class=line><span class=cl>            (dense): Linear(in_features=768, out_features=768, bias=True)
</span></span><span class=line><span class=cl>            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
</span></span><span class=line><span class=cl>            (dropout): Dropout(p=0.1, inplace=False)
</span></span><span class=line><span class=cl>          )
</span></span><span class=line><span class=cl>        )
</span></span><span class=line><span class=cl>        (intermediate): BertIntermediate(
</span></span><span class=line><span class=cl>          (dense): Linear(in_features=768, out_features=3072, bias=True)
</span></span><span class=line><span class=cl>          (intermediate_act_fn): GELUActivation()
</span></span><span class=line><span class=cl>        )
</span></span><span class=line><span class=cl>        (output): BertOutput(
</span></span><span class=line><span class=cl>          (dense): Linear(in_features=3072, out_features=768, bias=True)
</span></span><span class=line><span class=cl>          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
</span></span><span class=line><span class=cl>          (dropout): Dropout(p=0.1, inplace=False)
</span></span><span class=line><span class=cl>        )
</span></span><span class=line><span class=cl>      )
</span></span><span class=line><span class=cl>    )
</span></span><span class=line><span class=cl>  )
</span></span><span class=line><span class=cl>  (pooler): BertPooler(
</span></span><span class=line><span class=cl>    (dense): Linear(in_features=768, out_features=768, bias=True)
</span></span><span class=line><span class=cl>    (activation): Tanh()
</span></span><span class=line><span class=cl>  )
</span></span><span class=line><span class=cl>)
</span></span></code></pre></td></tr></table></div></div><p>å¯ä»¥ç”¨ä»¥ä¸‹ä»£ç è®¡ç®—æ¯ä¸€éƒ¨åˆ†çš„å‚æ•°é‡ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>total_params</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=n>total_learnable_params</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=n>total_embedding_params</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=n>total_encoder_params</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=n>total_pooler_params</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=c1># print(name, &#39;-&gt;&#39;, param.shape, &#39;-&gt;&#39;, param.numel())</span>
</span></span><span class=line><span class=cl>    <span class=c1># åŠ ä¸Š`if param.requires_grad:`å¯ä»¥è®¡ç®—å¯å­¦ä¹ å‚æ•°é‡</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=s1>&#39;embedding&#39;</span> <span class=ow>in</span> <span class=n>name</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>total_embedding_params</span> <span class=o>+=</span> <span class=n>param</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=s1>&#39;encoder&#39;</span> <span class=ow>in</span> <span class=n>name</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>total_encoder_params</span> <span class=o>+=</span> <span class=n>param</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=s1>&#39;pooler&#39;</span> <span class=ow>in</span> <span class=n>name</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>total_pooler_params</span> <span class=o>+=</span> <span class=n>param</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>total_learnable_params</span> <span class=o>+=</span> <span class=n>param</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>total_params</span> <span class=o>+=</span> <span class=n>param</span><span class=o>.</span><span class=n>numel</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>params</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=s2>&#34;total_embedding_params&#34;</span><span class=p>,</span> <span class=n>total_embedding_params</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=s2>&#34;total_encoder_params&#34;</span><span class=p>,</span> <span class=n>total_encoder_params</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=p>(</span><span class=s2>&#34;total_pooler_params&#34;</span><span class=p>,</span> <span class=n>total_pooler_params</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>params</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>percentage</span> <span class=o>=</span> <span class=p>(</span><span class=n>param</span> <span class=o>/</span> <span class=n>total_params</span><span class=p>)</span> <span class=o>*</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>percentage</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> %, </span><span class=si>{</span><span class=n>param</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>å¾—åˆ°è¾“å‡ºç»“æœï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>total_embedding_params: 21.77 %, <span class=m>23837184</span>
</span></span><span class=line><span class=cl>total_encoder_params: 77.69 %, <span class=m>85054464</span>
</span></span><span class=line><span class=cl>total_pooler_params: 0.54 %, <span class=m>590592</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=output>Output</h4><p>åœ¨<code>outputs = model(**input)</code>åè°ƒç”¨<code>type(outputs)</code>å¯ä»¥å‘ç°Bertçš„è¾“å‡ºç±»å‹æ˜¯<code>transformers.modeling_outputs.BaseModelOutputWithPoolingAndCrossAttentions</code>ã€‚å‚è€ƒ<a class=link href=https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertModel target=_blank rel=noopener>Huggingface-BERTæ–‡æ¡£</a>ï¼Œé»˜è®¤æƒ…å†µä¸‹é•¿åº¦ä¸º2ï¼ˆ<code>last_hidden_state</code>å’Œ<code>pooler_output</code>ï¼‰ã€‚å½“å®šä¹‰æ¨¡å‹æ—¶æŒ‡å®š<code>output_hidden_states=True</code>æ—¶ï¼Œè¿˜ä¼šè¿”å›<code>hidden_state</code>ï¼Œå…¶ä»–å‚æ•°ç±»ä¼¼ã€‚</p><ul><li><p>output[0] (<code>last_hidden_state</code>), shape = (batch_size, seq_len, hidden_size)</p></li><li><p>output[1] (<code>pooler_output</code>), shape = (batch_size, hidden_size)</p></li></ul><p>æœ€ç»ˆéšè—çŠ¶æ€ï¼ˆclassification token, [CLS]çš„è¾“å‡ºï¼‰</p><ul><li>output[2] (<code>hidden_states</code>), <strong>tuple</strong>, embedding layerå’Œæ¯ä¸ªlayerçš„è¾“å‡ºï¼ˆ1+12ï¼‰, shape = 13 * (batch_size, seq_len, hidden_size)</li></ul><p>å¦‚<code>model.embeddings(input['input_ids'], input['token_type_ids']) == outputs[2][0]</code>è¡¨ç¤ºEmbeddingå±‚çš„è¾“å‡ºã€‚</p><h3 id=embedding>Embedding</h3><p>ä¸Šæ–‡æåˆ°ï¼ŒBERTçš„Embeddingå±‚ç”±word embeddingsã€position embeddingså’Œtoken type embeddingä¸‰éƒ¨åˆ†ç»„æˆï¼Œä»¥ä¸‹ä»£ç å®ç°äº†ç®€å•çš„Embeddingå±‚ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>BertTokenizer</span><span class=p>,</span> <span class=n>BertModel</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>BertTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;bert-base-uncased&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>BertModel</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;bert-base-uncased&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>input</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=p>(</span><span class=n>sentence</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s1>&#39;pt&#39;</span><span class=p>)</span> <span class=c1># {input_ids, token_type_ids, attention_mask}</span>
</span></span><span class=line><span class=cl><span class=n>input_ids</span> <span class=o>=</span> <span class=nb>input</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>]</span>              <span class=c1># shape = (batch_size, token_len)</span>
</span></span><span class=line><span class=cl><span class=n>token_type_ids</span> <span class=o>=</span> <span class=nb>input</span><span class=p>[</span><span class=s1>&#39;token_type_ids&#39;</span><span class=p>]</span>    <span class=c1># shape = (batch_size, token_len)</span>
</span></span><span class=line><span class=cl><span class=n>pos_ids</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=n>input_ids</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>  <span class=c1># shape = (token_len)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. Word Embedding</span>
</span></span><span class=line><span class=cl><span class=n>word_embed</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>embeddings</span><span class=o>.</span><span class=n>word_embeddings</span><span class=p>(</span><span class=n>input_ids</span><span class=p>)</span>            <span class=c1># shape = (batch_size, token_len, embedding_size=768)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. Token Type Embedding</span>
</span></span><span class=line><span class=cl><span class=n>tok_embed</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>embeddings</span><span class=o>.</span><span class=n>token_type_embeddings</span><span class=p>(</span><span class=n>token_type_ids</span><span class=p>)</span>  <span class=c1># shape = (batch_size, token_len, embedding_size=768)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. Position Embedding</span>
</span></span><span class=line><span class=cl><span class=n>pos_embed</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>embeddings</span><span class=o>.</span><span class=n>position_embeddings</span><span class=p>(</span><span class=n>pos_ids</span><span class=p>)</span>           <span class=c1># shape = (token_len, embedding_size=768)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># **Input Embedding**</span>
</span></span><span class=line><span class=cl><span class=n>input_embed</span> <span class=o>=</span> <span class=n>word_embed</span> <span class=o>+</span> <span class=n>tok_embed</span> <span class=o>+</span> <span class=n>pos_embed</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>       <span class=c1># ä¹Ÿå¯ä»¥ä¸unsqueeze, ä¼šbroadcastçš„</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># åå¤„ç†</span>
</span></span><span class=line><span class=cl><span class=n>embed</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>embeddings</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>input_embed</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>embed</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>embeddings</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>embed</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=self-attention>Self-Attention</h3>$$Attention(Q, K, V)=softmax(\frac{QK^{T}}{\sqrt[]{d_{k}} })V$$<p>æ¥ä¸‹æ¥æ˜¯ä»Embeddingå±‚è¾“å‡ºåˆ°Multi-Head Self-Attention (MHA)çš„ä»£ç å®ç°ï¼ˆfirst headï¼‰ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>att_head_size</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>hidden_size</span> <span class=o>/</span> <span class=n>model</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>num_attention_heads</span><span class=p>)</span> <span class=c1># 768 / 12 = 64</span>
</span></span><span class=line><span class=cl><span class=n>emb_output</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>embeddings</span><span class=p>(</span><span class=nb>input</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>],</span> <span class=nb>input</span><span class=p>[</span><span class=s1>&#39;token_type_ids&#39;</span><span class=p>])</span> <span class=c1># shape = (batch_size, seq_len, embedding_dim)</span>
</span></span><span class=line><span class=cl><span class=c1># emb_output[0].shape = (seq_len, embedding_dim)</span>
</span></span><span class=line><span class=cl><span class=c1>## Why Transpose? å› ä¸ºPyTorchä¸­çš„Linearé‡Œå°±æ˜¯x@A^Tï¼ˆå·¦ä¹˜è½¬ç½®ï¼‰</span>
</span></span><span class=line><span class=cl><span class=n>Q_first_head_first_layer</span> <span class=o>=</span> <span class=n>emb_output</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>@</span> <span class=n>model</span><span class=o>.</span><span class=n>encoder</span><span class=o>.</span><span class=n>layer</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>attention</span><span class=o>.</span><span class=n>self</span><span class=o>.</span><span class=n>query</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>T</span><span class=p>[:,</span> <span class=p>:</span><span class=n>att_head_size</span><span class=p>]</span> <span class=o>+</span> <span class=n>model</span><span class=o>.</span><span class=n>encoder</span><span class=o>.</span><span class=n>layer</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>attention</span><span class=o>.</span><span class=n>self</span><span class=o>.</span><span class=n>query</span><span class=o>.</span><span class=n>bias</span><span class=p>[:</span><span class=n>att_head_size</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>K_first_head_first_layer</span> <span class=o>=</span> <span class=n>emb_output</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>@</span> <span class=n>model</span><span class=o>.</span><span class=n>encoder</span><span class=o>.</span><span class=n>layer</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>attention</span><span class=o>.</span><span class=n>self</span><span class=o>.</span><span class=n>key</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>T</span><span class=p>[:,</span> <span class=p>:</span><span class=n>att_head_size</span><span class=p>]</span> <span class=o>+</span> <span class=n>model</span><span class=o>.</span><span class=n>encoder</span><span class=o>.</span><span class=n>layer</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>attention</span><span class=o>.</span><span class=n>self</span><span class=o>.</span><span class=n>key</span><span class=o>.</span><span class=n>bias</span><span class=p>[:</span><span class=n>att_head_size</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=c1># (seq_len, att_head_size) @ (seq_len, att_head_size).T -&gt; (seq_len, seq_len)</span>
</span></span><span class=line><span class=cl><span class=n>attn_scores</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>nn</span><span class=o>.</span><span class=n>Softmax</span><span class=p>(</span><span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)(</span><span class=n>Q_first_head_first_layer</span> <span class=o>@</span> <span class=n>K_first_head_first_layer</span><span class=o>.</span><span class=n>T</span><span class=p>)</span> <span class=o>/</span> <span class=n>math</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=n>att_head_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>V_first_head_first_layer</span> <span class=o>=</span> <span class=n>emb_output</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>@</span> <span class=n>model</span><span class=o>.</span><span class=n>encoder</span><span class=o>.</span><span class=n>layer</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>attention</span><span class=o>.</span><span class=n>self</span><span class=o>.</span><span class=n>value</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>T</span><span class=p>[:,</span> <span class=p>:</span><span class=n>att_head_size</span><span class=p>]</span> <span class=o>+</span> <span class=n>model</span><span class=o>.</span><span class=n>encoder</span><span class=o>.</span><span class=n>layer</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>attention</span><span class=o>.</span><span class=n>self</span><span class=o>.</span><span class=n>value</span><span class=o>.</span><span class=n>bias</span><span class=p>[:</span><span class=n>att_head_size</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>attn_emb</span> <span class=o>=</span> <span class=n>attn_scores</span> <span class=o>@</span> <span class=n>V_first_head_first_layer</span> <span class=c1># shape = (seq_len, att_head_size)</span>
</span></span></code></pre></td></tr></table></div></div><p>æ¥ä¸‹æ¥æ˜¯å…³äºMHAçš„å…¬å¼æ¨å¯¼ï¼Œå®šä¹‰$E$ä¸ºEmbeddingå±‚çš„è¾“å‡º$q$ã€$k$ã€$v$åˆ†åˆ«ä¸ºåŒä¸€tokenå¯¹åº”çš„queryã€keyã€valueï¼Œ$W_q$ã€$W_k$ã€$W_v$åˆ†åˆ«ä¸ºåŒä¸€tokençš„æƒé‡ï¼Œ$Q$ã€$K$ã€$V$åˆ†åˆ«ä¸ºæ•´ä¸ªåºåˆ—çš„queryã€keyã€valueï¼Œ$W_Q$ã€$W_K$ã€$W_V$åˆ†åˆ«ä¸ºæ•´ä¸ªåºåˆ—çš„æƒé‡ã€‚è¿™é‡Œçœç•¥biasé¡¹ã€‚</p><p>å…ˆä»æŸä¸€tokenå‡ºå‘ï¼Œ$T$è¡¨ç¤ºåºåˆ—é•¿åº¦ï¼Œ$d_e$è¡¨ç¤ºEmbeddingå±‚ç»´åº¦ï¼Œ$d_q$ã€$d_k$ã€$d_v$åˆ†åˆ«è¡¨ç¤ºqã€kã€vçš„ç»´åº¦ï¼Œ$E \in \mathbb{R}^{T \times d_e}$ï¼Œé‚£ä¹ˆï¼š</p>$$E \cdot W_q = q \in \mathbb{R}^{T \times d_q}$$$$E \cdot W_k = k \in \mathbb{R}^{T \times d_k}$$$$E \cdot W_v = v \in \mathbb{R}^{T \times d_v}$$<p>å…¶ä¸­$d_q == d_k$ï¼Œå› ä¸ºåç»­éœ€è¦è®¡ç®—$q \cdot k^{T}$ï¼Œ$d_v$åˆ™æ²¡æœ‰è¦æ±‚ï¼š</p>$$Attention\ Score = Softmax(\frac{q \cdot k^{T}}{\sqrt{d_k}}) \in \mathbb{R}^{T \times T}$$$$Attention\ Output = Softmax(\frac{q \cdot k^{T}}{\sqrt{d_k}}) \cdot v \in \mathbb{R}^{T \times d_v}$$<p>æ¥ä¸‹æ¥å®šä¹‰Attentionå¤´æ•°ä¸º$n$ï¼Œå°†å•å¤´çš„æƒ…å†µæ‹“å±•åˆ°å¤šå¤´ï¼š</p>\[
\left[
\begin{array}{c|c|c|c}
E\cdot W_{q_1} & E\cdot W_{q_2} & ... & E\cdot W_{q_n} \\
\end{array}
\right]=E\cdot \left[
\begin{array}{c|c|c|c}
W_{q_1} & W_{q_2} & ... & W_{q_n} \\
\end{array}
\right]=E\cdot W_Q=Q \in \mathbb{R}^{T \times n\cdot d_q}
\]\[
\left[
\begin{array}{c|c|c|c}
E\cdot W_{k_1} & E\cdot W_{k_2} & ... & E\cdot W_{k_n} \\
\end{array}
\right]=E\cdot \left[
\begin{array}{c|c|c|c}
W_{k_1} & W_{k_2} & ... & W_{k_n} \\
\end{array}
\right]=E\cdot W_K=K \in \mathbb{R}^{T \times n\cdot d_k}
\]\[
\left[
\begin{array}{c|c|c|c}
E\cdot W_{v_1} & E\cdot W_{v_2} & ... & E\cdot W_{v_n} \\
\end{array}
\right]=E\cdot \left[
\begin{array}{c|c|c|c}
W_{v_1} & W_{v_2} & ... & W_{v_n} \\
\end{array}
\right]=E\cdot W_V=V \in \mathbb{R}^{T \times n\cdot d_v}
\]<p>é‚£ä¹ˆå°±å¯ä»¥å¾—åˆ°å®Œæ•´çš„MHAäº†ï¼š</p>$$Attention(Q, K, V)=softmax(\frac{QK^{T}}{\sqrt[]{d_{k}} })V \in \mathbb{R}^{T \times n \cdot d_v}$$<h3 id=add--norm>Add & Norm</h3><figure><img src=/p/llm1/img/2.png width='200px"'><figcaption><h4>Encoder of Transformer</h4></figcaption></figure><p>åœ¨Encoderä¸­å…±æœ‰ä¸¤æ¬¡å‚å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–ï¼ˆAdd & Normï¼‰ï¼Œç¬¬ä¸€æ¬¡å‘ç”Ÿåœ¨MHAä¸­ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>layer</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>encoder</span><span class=o>.</span><span class=n>layer</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>    <span class=c1># First Layer</span>
</span></span><span class=line><span class=cl><span class=n>embeddings</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=nb>input</span><span class=p>)[</span><span class=mi>2</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span> <span class=c1># Embeddings Layer Output</span>
</span></span><span class=line><span class=cl><span class=n>mha_output</span> <span class=o>=</span> <span class=n>layer</span><span class=o>.</span><span class=n>attention</span><span class=o>.</span><span class=n>self</span><span class=p>(</span><span class=n>embeddings</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>attn_output</span> <span class=o>=</span> <span class=n>layer</span><span class=o>.</span><span class=n>attention</span><span class=o>.</span><span class=n>output</span><span class=p>(</span><span class=n>mha_output</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>embeddings</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>ç¬¬äºŒæ¬¡å‘ç”Ÿåœ¨MLPä¸­ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>mlp1</span> <span class=o>=</span> <span class=n>layer</span><span class=o>.</span><span class=n>intermediate</span><span class=p>(</span><span class=n>attn_output</span><span class=p>)</span> <span class=c1># shape = (batch_size, seq_len, 4x768)</span>
</span></span><span class=line><span class=cl><span class=n>mlp2</span> <span class=o>=</span> <span class=n>layer</span><span class=o>.</span><span class=n>output</span><span class=o>.</span><span class=n>output</span><span class=p>(</span><span class=n>mlp1</span><span class=p>,</span> <span class=n>attn_output</span><span class=p>)</span> <span class=c1># è¿™ä¸ªç»“æœå’Œoutput[2][1]æ˜¯ç›¸åŒçš„ï¼ˆlayer 1çš„è¾“å‡ºç»“æœï¼‰</span>
</span></span></code></pre></td></tr></table></div></div><p><code>Add & Norm</code>çš„å®ç°å¾ˆç®€å•ï¼Œå¦‚ä¸‹ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>hidden_states</span><span class=p>,</span> <span class=n>input_tensor</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=n>hidden_states</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dense</span><span class=p>(</span><span class=n>hidden_states</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>hidden_states</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dropout</span><span class=p>(</span><span class=n>hidden_states</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>hidden_states</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>hidden_states</span> <span class=o>+</span> <span class=n>input_tensor</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>hidden_states</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=pooler>Pooler</h3><p>å¯¹äº<code>output = model(**input)</code>ï¼Œä¸€èˆ¬æœ‰ä¸¤ä¸ªkeysï¼Œå³<code>last_hidden_state</code>(shape=(batch_size, seq_len, emb_dim))å’Œ<code>pooler_output</code>(shape=(batch_size, emb_dim))ã€‚</p><p>å…¶ä¸­<code>pooler_output</code>å°‘äº†seq_lençš„ç»´åº¦ï¼Œè§‚å¯ŸBERTæºç å¯ä»¥å‘ç°ï¼Œ<code>pooler_output</code>æ˜¯BERT encoderåªå¯¹ç¬¬ä¸€ä¸ªtokenï¼ˆä¹Ÿå°±æ˜¯[CLS]ï¼‰è¿›è¡Œäº†ä¸€æ¬¡å…¨è¿æ¥å’Œæ¿€æ´»çš„è¾“å‡ºã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>hidden_states</span><span class=p>):</span>
</span></span><span class=line><span class=cl>  <span class=c1># We &#34;pool&#34; the model by simply taking the hidden state corresponding</span>
</span></span><span class=line><span class=cl>  <span class=c1># to the first token.</span>
</span></span><span class=line><span class=cl>  <span class=n>first_token_tensor</span> <span class=o>=</span> <span class=n>hidden_states</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span> <span class=c1># ç¬¬ä¸€ä¸ªå…ƒç´ çš„hidden_states</span>
</span></span><span class=line><span class=cl>  <span class=n>pooled_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>dense</span><span class=p>(</span><span class=n>first_token_tensor</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=n>pooled_output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>activation</span><span class=p>(</span><span class=n>pooled_output</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=k>return</span> <span class=n>pooled_output</span>
</span></span></code></pre></td></tr></table></div></div><p>ä¹Ÿå¯ä»¥ç¿»è¯‘ä¸ºä»¥ä¸‹ä»£ç ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>first_sentence</span> <span class=o>=</span> <span class=n>output</span><span class=p>[</span><span class=s1>&#39;last_hidden_state&#39;</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>pool_output</span> <span class=o>=</span> <span class=n>bert</span><span class=o>.</span><span class=n>pooler</span><span class=o>.</span><span class=n>dense</span><span class=p>(</span><span class=n>first_sentence</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=p>:])</span>
</span></span><span class=line><span class=cl><span class=n>pool_output</span> <span class=o>=</span> <span class=n>bert</span><span class=o>.</span><span class=n>pooler</span><span class=o>.</span><span class=n>activation</span><span class=p>(</span><span class=n>pool_output</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>ä¸‹é¢çš„å›¾å¯ä»¥æ¸…æ™°åœ°è¯ é‡Šè¿™ä¸€è¿‡ç¨‹ï¼š</p><figure><img src=/p/llm1/img/4.png width='500px"'><figcaption><h4>Chris McCormickçš„å¥½å›¾</h4></figcaption></figure><p>è¿™ä¸€Pooler Layerå¯ä»¥è§†ä¸ºBERTçš„ä¸€ä¸ªé»˜è®¤headï¼Œä½œä¸ºæœ€åBERTçš„è¾“å‡ºã€‚åœ¨ä¸åŒçš„ä»»åŠ¡ä¸‹ï¼Œä¸€èˆ¬ä¿ç•™åŒæ ·çš„Embedding Layerå’Œä¸­é—´Layerï¼Œåªæ›¿æ¢æœ€åè¿™ä¸€éƒ¨åˆ†ã€‚</p><h2 id=masked-language-model>Masked Language Model</h2><p>æ©ç è¯­è¨€æ¨¡å‹ï¼ˆMLM, Masked Language Modelï¼‰æ˜¯BERTçš„ä¸€ç§è‡ªç›‘ç£å­¦ä¹ ä»»åŠ¡ï¼Œæ¨¡å‹çš„ç›®æ ‡æ˜¯é¢„æµ‹è¾“å…¥æ–‡æœ¬ä¸­è¢«éšæœºè¦†ç›–ï¼ˆmaskedï¼‰çš„tokenï¼ˆå®Œå½¢å¡«ç©ºï¼‰ã€‚å½“æˆ‘ä»¬ä½¿ç”¨<code>BertForMaskedLM</code>åŠ è½½æ¨¡å‹åï¼Œè§‚å¯Ÿé…ç½®ï¼ˆä¸»è¦å…³æ³¨æœ€åä¸€å±‚ï¼‰ã€‚</p><h3 id=cls-layer>CLS Layer</h3><p>BERTï¼ˆbaseï¼‰çš„æœ€åä¸€å±‚æ˜¯ä¸Šä¸€èŠ‚æåˆ°çš„ç®€å•çš„Pooler Playerï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>(pooler): BertPooler(
</span></span><span class=line><span class=cl>  (dense): Linear(in_features=768, out_features=768, bias=True)
</span></span><span class=line><span class=cl>  (activation): Tanh()
</span></span><span class=line><span class=cl>)
</span></span></code></pre></td></tr></table></div></div><p>è€ŒBERTï¼ˆMLMï¼‰çš„æœ€åä¸€å±‚æ˜¯ä¸€ä¸ªç•¥å¾®å¤æ‚ä¸€äº›çš„CLS Layerï¼Œç”±transformï¼ˆå…¨è¿æ¥+æ¿€æ´»+å±‚å½’ä¸€åŒ–ï¼‰å’Œdecoderï¼ˆå…¨è¿æ¥ï¼‰ä¸¤ä¸ªè¿ç®—æ„æˆï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>(cls): BertOnlyMLMHead(
</span></span><span class=line><span class=cl>  (predictions): BertLMPredictionHead(
</span></span><span class=line><span class=cl>    (transform): BertPredictionHeadTransform(
</span></span><span class=line><span class=cl>      (dense): Linear(in_features=768, out_features=768, bias=True)
</span></span><span class=line><span class=cl>      (transform_act_fn): GELUActivation()
</span></span><span class=line><span class=cl>      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
</span></span><span class=line><span class=cl>    )
</span></span><span class=line><span class=cl>    (decoder): Linear(in_features=768, out_features=30522, bias=True)
</span></span><span class=line><span class=cl>  )
</span></span><span class=line><span class=cl>)
</span></span></code></pre></td></tr></table></div></div><p>ç»è¿‡<code>self.transform</code>è¿ç®—åï¼Œä»ç„¶ä¿æŒshape=(batch_size, seq_len, emb_dim=768)ï¼Œä½œç”¨ä»…ä»…æ˜¯åšä¸€æ¬¡åŒæ ·ç»´åº¦çš„å…¨è¿æ¥æ¿€æ´»ï¼›<code>self.decoder</code>ä¹Ÿåªæ˜¯ä¸€ä¸ªç®€å•çš„å…¨è¿æ¥ï¼Œå°†768ç»´æ˜ å°„åˆ°vocab_size=30522ç»´ï¼ˆå¤šåˆ†ç±»ä»»åŠ¡ï¼‰ã€‚</p><h3 id=masking>Masking</h3><p>æ—¢ç„¶æ˜¯ç›‘ç£å­¦ä¹ ï¼Œå°±éœ€è¦åˆ¶ä½œLabeläº†ã€‚ä»¥ä¸‹ä»£ç å¯ä»¥å¯¹ç»è¿‡tokenizerçš„æ–‡æœ¬è¿›è¡Œéšæœºmaskå¹¶åŠ å…¥labelæ ‡è®°åŸå§‹æ–‡æœ¬ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=p>(</span><span class=n>text</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s1>&#39;pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span><span class=p>[</span><span class=s1>&#39;labels&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>inputs</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>clone</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># ç”Ÿæˆæ©ç çŸ©é˜µï¼ˆåºåˆ—ï¼‰</span>
</span></span><span class=line><span class=cl><span class=n>mask_arr</span> <span class=o>=</span> <span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=n>inputs</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span> <span class=o>&lt;</span> <span class=mf>0.15</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=n>inputs</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>]</span> <span class=o>!=</span> <span class=mi>101</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=n>inputs</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>]</span> <span class=o>!=</span> <span class=mi>102</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># ç­›é€‰æ©ç åˆ—è¡¨</span>
</span></span><span class=line><span class=cl><span class=n>selection</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=n>mask_arr</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>nonzero</span><span class=p>())</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=c1># éšæœºmask</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>][</span><span class=mi>0</span><span class=p>,</span> <span class=n>selection</span><span class=p>]</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>vocab</span><span class=p>[</span><span class=s1>&#39;[MASK]&#39;</span><span class=p>]</span> <span class=c1># or 103</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=computing-process>Computing Process</h3><p>ä¸Baseæ¨¡å‹çš„Pooler Layerå°†æœ€åä¸€å±‚çš„ç¬¬ä¸€ä¸ªtokençš„éšè—çŠ¶æ€ä½œä¸ºè¾“å…¥ä¸åŒï¼ŒMLMå°†æœ€åä¸€å±‚çš„æ‰€æœ‰éšè—çŠ¶æ€ä½œä¸ºè¾“å‡ºï¼Œå³<code>mlm_output = mlm.cls(outputs['hidden_states'][-1])</code>ã€‚å®é™…ä¸Šå°±æ˜¯è¿™ä¹ˆä¸ªæµç¨‹ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>mlm</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>last_hidden_state</span> <span class=o>=</span> <span class=n>outputs</span><span class=p>[</span><span class=s1>&#39;hidden_states&#39;</span><span class=p>][</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>                    <span class=c1># (batch_size, seq_len, emb_dim)</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>transformed</span> <span class=o>=</span> <span class=n>mlm</span><span class=o>.</span><span class=n>cls</span><span class=o>.</span><span class=n>predictions</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>last_hidden_state</span><span class=p>)</span>  <span class=c1># (batch_size, seq_len, emb_dim) still</span>
</span></span><span class=line><span class=cl>    <span class=n>logits</span> <span class=o>=</span> <span class=n>mlm</span><span class=o>.</span><span class=n>cls</span><span class=o>.</span><span class=n>predictions</span><span class=o>.</span><span class=n>decoder</span><span class=p>(</span><span class=n>transformed</span><span class=p>)</span>               <span class=c1># (batch_size, seq_len, vocab_size)</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=loss--translate>Loss & Translate</h3><p><code>mlm(**inputs)</code>çš„è¿”å›ç±»å‹æ˜¯<code>transformers.modeling_outputs.MaskedLMOutput</code>ï¼Œå³<code>odict_keys(['loss', 'logits', 'hidden_states'])</code>ã€‚</p><p><code>output.loss</code>æ˜¯ä¸€ä¸ªtensoræ ‡é‡ï¼Œä½¿ç”¨CrossEntropyï¼Œå®ç°å¦‚ä¸‹ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>ce</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>outputs</span><span class=o>.</span><span class=n>loss</span> <span class=o>=</span> <span class=n>ce</span><span class=p>(</span><span class=n>logits</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>inputs</span><span class=p>[</span><span class=s1>&#39;labels&#39;</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>))</span>
</span></span></code></pre></td></tr></table></div></div><p>è€Œç¿»è¯‘ä¹Ÿå¾ˆç®€å•ï¼Œä½¿ç”¨<code>torch.argmax(logits[0], dim=1)</code>æ‰¾åˆ°æœ€å¤§æ¦‚ç‡åˆ†æ•°çš„ç´¢å¼•å³å¯ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s1>&#39; &#39;</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>convert_ids_to_tokens</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>logits</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)))</span>
</span></span></code></pre></td></tr></table></div></div><h2 id=fine-tuning-task-text-classification>Fine-Tuning Task (Text Classification)</h2><p>è¿™é‡Œå‚è€ƒ<a class=link href="https://www.bilibili.com/video/BV1tM411L7HE/?spm_id_from=333.1387.collection.video_card.click" target=_blank rel=noopener>fine tune transformers æ–‡æœ¬åˆ†ç±»/æƒ…æ„Ÿåˆ†æ</a>æ•™ç¨‹ï¼Œå®ç°ä¸€ä¸ªåŸºäºBERTçš„æƒ…æ„Ÿåˆ†æçš„å…¨æµç¨‹å…¨å‚å¾®è°ƒä»»åŠ¡ã€‚æƒ…æ„Ÿåˆ†ææ˜¯æ–‡æœ¬/åºåˆ—åˆ†ç±»ä»»åŠ¡çš„ä¸€ç§ï¼Œå®è´¨ä¸Šå°±æ˜¯å¯¹æ–‡æœ¬/åºåˆ—è¿›è¡Œå¤šåˆ†ç±»çš„è‡ªç›‘ç£å­¦ä¹ ã€‚</p><h3 id=data>Data</h3><h4 id=data-load---emotions>Data Load - emotions</h4><p>è¿™é‡Œé€‰æ‹©ä½¿ç”¨emotionsæ•°æ®é›†ï¼Œå¸¸ç”¨äºæ–‡æœ¬æƒ…æ„Ÿåˆ†ç±»ï¼Œè¯†åˆ«å¥å­æˆ–æ®µè½ä¸­è¡¨è¾¾çš„æƒ…æ„Ÿç±»åˆ«ï¼ŒåŒ…æ‹¬6ç±»æ ‡ç­¾ï¼ˆsadness, joy, love, anger, fear, surpriseï¼‰ã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_dataset</span>
</span></span><span class=line><span class=cl><span class=n>emotions</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=s2>&#34;emotions&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>é€šè¿‡æ‰“å°<code>emotions</code>å¯ä»¥çœ‹åˆ°emotionsæ•°æ®é›†çš„ç»„æˆï¼Œå…±æœ‰ä¸¤ä¸‡æ¡æ•°æ®ï¼Œ$Size_{Train} : Size_{Vali} : Size_{Test} = 8 : 1 : 1$ï¼Œæ¯ä¸ªæ•°æ®æœ‰<code>text</code>å’Œ<code>label</code>ä¸¤ä¸ªfeaturesï¼ˆdict of dictï¼‰ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl>DatasetDict({
</span></span><span class=line><span class=cl>    train: Dataset({
</span></span><span class=line><span class=cl>        features: [&#39;text&#39;, &#39;label&#39;],
</span></span><span class=line><span class=cl>        num_rows: 16000
</span></span><span class=line><span class=cl>    })
</span></span><span class=line><span class=cl>    validation: Dataset({
</span></span><span class=line><span class=cl>        features: [&#39;text&#39;, &#39;label&#39;],
</span></span><span class=line><span class=cl>        num_rows: 2000
</span></span><span class=line><span class=cl>    })
</span></span><span class=line><span class=cl>    test: Dataset({
</span></span><span class=line><span class=cl>        features: [&#39;text&#39;, &#39;label&#39;],
</span></span><span class=line><span class=cl>        num_rows: 2000
</span></span><span class=line><span class=cl>    })
</span></span><span class=line><span class=cl>})
</span></span></code></pre></td></tr></table></div></div><p><code>labels = emotions['train'].features['label'].names</code>å¯ä»¥æŸ¥çœ‹å„ä¸ªæ ‡ç­¾ã€‚</p><h4 id=data-visualization-analysis>Data Visualization Analysis</h4><p>ç®€å•å¯è§†åŒ–åˆ†æä¸€ä¸‹æ•°æ®é›†ï¼Œä¸»è¦ä»»åŠ¡æœ‰ï¼š</p><ul><li><p>å°†<code>dataset</code>è½¬åŒ–ä¸º<code>dataframe</code>ï¼Œæ–¹ä¾¿åç»­æ“ä½œ</p></li><li><p>åˆ†ææ–‡æœ¬é•¿åº¦å’Œæ ‡ç­¾é¢‘ç‡</p></li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Task 1: dataset -&gt; dataframe</span>
</span></span><span class=line><span class=cl><span class=n>emotions_df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=o>.</span><span class=n>from_dict</span><span class=p>(</span><span class=n>emotions</span><span class=p>[</span><span class=s1>&#39;train&#39;</span><span class=p>])</span> <span class=c1># å–å‡ºè®­ç»ƒé›†</span>
</span></span><span class=line><span class=cl><span class=n>emotions_df</span><span class=p>[</span><span class=s1>&#39;label_name&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>emotions_df</span><span class=p>[</span><span class=s1>&#39;label&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=k>lambda</span> <span class=n>x</span><span class=p>:</span> <span class=n>labels</span><span class=p>[</span><span class=n>x</span><span class=p>])</span> <span class=c1># åŠ å…¥æ ‡ç­¾ååˆ—</span>
</span></span><span class=line><span class=cl><span class=n>emotions_df</span><span class=p>[</span><span class=s1>&#39;words per tweet&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>emotions_df</span><span class=p>[</span><span class=s1>&#39;text&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>str</span><span class=o>.</span><span class=n>split</span><span class=p>()</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=nb>len</span><span class=p>)</span> <span class=c1># ç»Ÿè®¡wordsæ•°</span>
</span></span></code></pre></td></tr></table></div></div><p>æ¥ä¸‹æ¥å¯ä»¥ç®€å•åˆ†æï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># ç»Ÿè®¡æ ‡ç­¾æ•°</span>
</span></span><span class=line><span class=cl><span class=n>emotions_df</span><span class=o>.</span><span class=n>label</span><span class=o>.</span><span class=n>value_counts</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>emotions_df</span><span class=o>.</span><span class=n>label_name</span><span class=o>.</span><span class=n>value_counts</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=c1># æŸ¥çœ‹æœ€é•¿/çŸ­æ–‡æœ¬</span>
</span></span><span class=line><span class=cl><span class=n>emotions_df</span><span class=p>[</span><span class=s1>&#39;words per tweet&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>max</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>emotions_df</span><span class=p>[</span><span class=s1>&#39;words per tweet&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>idxmax</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>emotions_df</span><span class=o>.</span><span class=n>iloc</span><span class=p>[</span><span class=o>...</span><span class=p>][</span><span class=s1>&#39;text&#39;</span><span class=p>]</span>
</span></span></code></pre></td></tr></table></div></div><p>ç®€å•çš„å¯è§†åŒ–ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Labels&#39; Freq</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>3</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>emotions_df</span><span class=p>[</span><span class=s1>&#39;label_name&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>value_counts</span><span class=p>(</span><span class=n>ascending</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span><span class=o>.</span><span class=n>plot</span><span class=o>.</span><span class=n>barh</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s1>&#39;freq of labels&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># Words / Tweet</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>3</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>emotions_df</span><span class=p>[</span><span class=s1>&#39;words per tweet&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>emotions_df</span><span class=p>[</span><span class=s1>&#39;text&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>str</span><span class=o>.</span><span class=n>split</span><span class=p>()</span><span class=o>.</span><span class=n>apply</span><span class=p>(</span><span class=nb>len</span><span class=p>)</span> <span class=c1># ç®€å•ç»Ÿè®¡</span>
</span></span><span class=line><span class=cl><span class=n>emotions_df</span><span class=o>.</span><span class=n>boxplot</span><span class=p>(</span><span class=s1>&#39;words per tweet&#39;</span><span class=p>,</span> <span class=n>by</span><span class=o>=</span><span class=s1>&#39;label_name&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>showfliers</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>grid</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;black&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>suptitle</span><span class=p>(</span><span class=s1>&#39;&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;&#39;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p><figure><img src=/p/llm1/img/5.png width='300px"'><figcaption><h4>æ ‡ç­¾é¢‘ç‡</h4></figcaption></figure><figure><img src=/p/llm1/img/6.png width='300px"'><figcaption><h4>æ–‡æœ¬é•¿åº¦</h4></figcaption></figure></p><h4 id=text2tokens>Text2Tokens</h4><p>ä¸ºäº†åç»­æ¨¡å‹çš„è®­ç»ƒï¼Œéœ€è¦å°†æ•°æ®é›†è½¬æ¢ä¸ºæ¨¡å‹æ¥å—çš„è¾“å…¥ç±»å‹ã€‚å¯¹äºmodelï¼Œéœ€è¦å…³æ³¨BERT/DistillBERTä½¿ç”¨subword tokenizerï¼›å¯¹äºtokenizerï¼Œéœ€è¦å…³æ³¨<code>tokenizer.vocab_size</code>ã€<code>model_max_length</code>å’Œ<code>model_input_name</code>å‡ ä¸ªå‚æ•°ã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoTokenizer</span>
</span></span><span class=line><span class=cl><span class=n>model_ckpt</span> <span class=o>=</span> <span class=s2>&#34;/path/to/bert-distill&#34;</span>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_ckpt</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>vocab_size</span><span class=p>,</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>model_max_length</span><span class=p>,</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>model_input_names</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 30522 512 [&#39;input_ids&#39;, &#39;attention_mask&#39;]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># è¾“å‡ºä¸€ä¸ªbatchçš„textï¼Œ è¾“å‡ºä¸€ä¸ªbatchçš„tokens</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>batch_tokenize</span><span class=p>(</span><span class=n>batch</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>tokenizer</span><span class=p>(</span><span class=n>batch</span><span class=p>[</span><span class=s1>&#39;text&#39;</span><span class=p>],</span> <span class=n>padding</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>truncation</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>emotions_encoded</span> <span class=o>=</span> <span class=n>emotions</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>batch_tokenize</span><span class=p>,</span> <span class=n>batched</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span> 
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># type(emotions_encoded[&#39;train&#39;][&#39;input_ids&#39;][0]) == list</span>
</span></span><span class=line><span class=cl><span class=c1># list to tensor</span>
</span></span><span class=line><span class=cl><span class=n>emotions_encoded</span><span class=o>.</span><span class=n>set_format</span><span class=p>(</span><span class=s1>&#39;torch&#39;</span><span class=p>,</span> <span class=n>columns</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>,</span> <span class=s1>&#39;attention_mask&#39;</span><span class=p>,</span> <span class=s1>&#39;label&#39;</span><span class=p>])</span>
</span></span></code></pre></td></tr></table></div></div><h3 id=model-fine-tuning>Model Fine-Tuning</h3><h4 id=load-model>Load Model</h4><p>DistillBERT-base-uncasedæ˜¯huggingfaceæä¾›çš„ä¸€ä¸ªè½»é‡çº§BERTæ¨¡å‹ï¼Œç”±çŸ¥è¯†è’¸é¦ï¼ˆKnowledge Distillationï¼‰æŠ€æœ¯è®­ç»ƒï¼Œåœ¨ä¿æŒé«˜æ€§èƒ½çš„åŒæ—¶å¤§å¹…å‡å°‘äº†æ¨¡å‹å‚æ•°ï¼Œä½¿æ¨ç†é€Ÿåº¦æ›´å¿«ã€è®¡ç®—èµ„æºéœ€æ±‚æ›´ä½ã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoModel</span>
</span></span><span class=line><span class=cl><span class=n>model_ckpt</span> <span class=o>=</span> <span class=s1>&#39;/home/HPC_ASC/bert-distill&#39;</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModel</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_ckpt</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><p>é€šè¿‡<code>model</code>å¯ä»¥å‘ç°ï¼Œç›¸è¾ƒäºBERT baselineï¼Œè¿™ä¸ªè’¸é¦åçš„æ¨¡å‹åœ¨Embedding Layerå‡å°‘äº†token_type_embeddingï¼ˆåªæœ‰word embeddingå’Œposition embeddingï¼‰ï¼Œå°†åŸæœ¬12å±‚Transformer Layeræ”¹ä¸º6å±‚ã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_params</span><span class=p>(</span><span class=n>model</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model_parameters</span> <span class=o>=</span> <span class=nb>filter</span><span class=p>(</span><span class=k>lambda</span> <span class=n>p</span><span class=p>:</span> <span class=n>p</span><span class=o>.</span><span class=n>requires_grad</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>())</span>
</span></span><span class=line><span class=cl>    <span class=n>params</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>([</span><span class=n>np</span><span class=o>.</span><span class=n>prod</span><span class=p>(</span><span class=n>p</span><span class=o>.</span><span class=n>size</span><span class=p>())</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>model_parameters</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>params</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>get_params</span><span class=p>(</span><span class=n>model</span><span class=p>)</span> <span class=c1># return np.int64(66362880) ç›¸è¾ƒäºbert-base-uncasedå°‘äº†çº¦40%å‚æ•°</span>
</span></span></code></pre></td></tr></table></div></div><p>æ¥ä¸‹æ¥åŠ è½½æ¨¡å‹ï¼Œå¯ä»¥é€šè¿‡<code>nvidia-smi</code>æˆ–<code>nvtop</code>ï¼ˆå¦‚æœæ­£ç¡®å®‰è£…å’Œé…ç½®äº†çš„è¯ï¼‰å¯ä»¥çœ‹åˆ°åŠ è½½åˆ°æ˜¾å­˜ä¸­çš„æ¨¡å‹å ç”¨çº¦546MiBã€‚</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoModelForSequenceClassification</span> <span class=c1># å’ŒAutoModelä¸åŒï¼Œåè€…æ²¡æœ‰åˆ†ç±»å¤´   -&gt; ä¸‹æ¸¸ä»»åŠ¡</span>
</span></span><span class=line><span class=cl><span class=n>modle_ckpt</span> <span class=o>=</span> <span class=s1>&#39;/home/HPC_ASC/distilbert-base-uncased&#39;</span>
</span></span><span class=line><span class=cl><span class=n>device</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>device</span><span class=p>(</span><span class=s1>&#39;cuda&#39;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s1>&#39;cpu&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForSequenceClassification</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_ckpt</span><span class=p>,</span> <span class=n>num_labels</span><span class=o>=</span><span class=n>num_classes</span><span class=p>,</span> <span class=n>ignore_mismatched_sizes</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=transformers-trainer>Transformers Trainer</h4><p>æˆ‘ä»¬éœ€è¦å¯¼å…¥å¹¶å®šä¹‰huggingfaceæä¾›çš„è®­ç»ƒAPIæ¥å®Œæˆé«˜æ•ˆçš„æ¨¡å‹è®­ç»ƒã€‚åœ¨æ­£å¼å®šä¹‰Trainerå‰ï¼Œè¿˜éœ€è¦ä¸€ä¸ªè¾…åŠ©å‡½æ•°æ¥ç¡®å®šTrainerçš„å‚æ•°æŒ‡æ ‡ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>compute_classification_metrics</span><span class=p>(</span><span class=n>pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># pred: PredictionOutput, from trainer.predict(dataset)</span>
</span></span><span class=line><span class=cl>    <span class=c1># true label</span>
</span></span><span class=line><span class=cl>    <span class=n>labels</span> <span class=o>=</span> <span class=n>pred</span><span class=o>.</span><span class=n>label_ids</span>
</span></span><span class=line><span class=cl>    <span class=c1># pred</span>
</span></span><span class=line><span class=cl>    <span class=n>preds</span> <span class=o>=</span> <span class=n>pred</span><span class=o>.</span><span class=n>predictions</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>f1</span> <span class=o>=</span> <span class=n>f1_score</span><span class=p>(</span><span class=n>labels</span><span class=p>,</span> <span class=n>preds</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s2>&#34;weighted&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>acc</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>labels</span><span class=p>,</span> <span class=n>preds</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>precision</span> <span class=o>=</span> <span class=n>precision_score</span><span class=p>(</span><span class=n>labels</span><span class=p>,</span> <span class=n>preds</span><span class=p>,</span> <span class=n>average</span><span class=o>=</span><span class=s2>&#34;macro&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span><span class=s2>&#34;accuracy&#34;</span><span class=p>:</span> <span class=n>acc</span><span class=p>,</span> <span class=s2>&#34;f1&#34;</span><span class=p>:</span> <span class=n>f1</span><span class=p>,</span> <span class=s2>&#34;precision&#34;</span><span class=p>:</span> <span class=n>precision</span><span class=p>}</span>
</span></span></code></pre></td></tr></table></div></div><p>æ¥ä¸‹æ¥æ­£å¼å®šä¹‰Trainerï¼ˆåœ¨è¿™ä¸€æ­¥å¯èƒ½ä¼šæç¤ºä½ éœ€è¦å®‰è£…<code>transformers[torch]</code>æˆ–<code>accelerator >= 0.26?</code>ï¼ŒåŠ¡å¿…ä¸è¦ç›´æ¥<code>pip install transformers[torch]</code>ï¼Œè¿™ä¼šå¯¼è‡´å¸è½½æˆ‘æœ¬åœ°å·²å®‰è£…çš„<code>torch (v2.7.0)</code>å¹¶å®‰è£…<code>torch (v2.6.0)</code>ï¼Œä»è€Œè®©<code>torchvision</code>ç­‰åŒ…çš„ç‰ˆæœ¬ä¸åŒ¹é…ï¼Œè¿›è€Œå¼•å‘æ›´å¤šé”™è¯¯ï¼‰ï¼Œå¹¶å¼€å§‹æ¨¡å‹è®­ç»ƒï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># https://huggingface.co/docs/transformers/main_classes/trainer</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>TrainingArguments</span><span class=p>,</span> <span class=n>Trainer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>batch_size</span> <span class=o>=</span> <span class=mi>64</span>
</span></span><span class=line><span class=cl><span class=n>logging_steps</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>emotions_encoded</span><span class=p>[</span><span class=s1>&#39;train&#39;</span><span class=p>])</span> <span class=o>//</span> <span class=n>batch_size</span>  <span class=c1># 160,000 // batch_size</span>
</span></span><span class=line><span class=cl><span class=n>model_name</span> <span class=o>=</span> <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>model_ckpt</span><span class=si>}</span><span class=s1>_emotion_ft_0531&#39;</span>
</span></span><span class=line><span class=cl><span class=n>training_args</span> <span class=o>=</span> <span class=n>TrainingArguments</span><span class=p>(</span><span class=n>output_dir</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                  <span class=n>num_train_epochs</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                  <span class=n>learning_rate</span><span class=o>=</span><span class=mf>2e-5</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                  <span class=n>weight_decay</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span> <span class=c1># é»˜è®¤ä½¿ç”¨AdamWçš„ä¼˜åŒ–ç®—æ³•</span>
</span></span><span class=line><span class=cl>                                  <span class=n>per_device_train_batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                  <span class=n>per_device_eval_batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                  <span class=n>eval_strategy</span><span class=o>=</span><span class=s2>&#34;epoch&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                  <span class=n>disable_tqdm</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                  <span class=n>logging_steps</span><span class=o>=</span><span class=n>logging_steps</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                  <span class=c1># write</span>
</span></span><span class=line><span class=cl>                                  <span class=n>push_to_hub</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                  <span class=n>log_level</span><span class=o>=</span><span class=s2>&#34;error&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>trainer</span> <span class=o>=</span> <span class=n>Trainer</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=n>tokenizer</span><span class=o>=</span><span class=n>tokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=n>train_dataset</span><span class=o>=</span><span class=n>emotions_encoded</span><span class=p>[</span><span class=s1>&#39;train&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                  <span class=n>eval_dataset</span><span class=o>=</span><span class=n>emotions_encoded</span><span class=p>[</span><span class=s1>&#39;validation&#39;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                  <span class=n>args</span><span class=o>=</span><span class=n>training_args</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                  <span class=n>compute_metrics</span><span class=o>=</span><span class=n>compute_classification_metrics</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>trainer</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><figure><img src=/p/llm1/img/11.png width='500px"'><figcaption><h4>nvtop: ç¡¬ä»¶ç¯å¢ƒæ˜¯ä¸€æœºå…«å¡Tesla P100 16G</h4></figcaption></figure><figure><img src=/p/llm1/img/8.png width='400px"'><figcaption><h4>Model Training</h4></figcaption></figure><p>è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡ä¼šå­˜æ”¾åœ¨å½“å‰ç›®å½•çš„<code>model_name</code>ï¼ˆbert-distill_emotion_ft_0531ï¼‰ä¸‹ã€‚</p><h4 id=inference>Inference</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>preds_output</span> <span class=o>=</span> <span class=n>trainer</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>emotions_encoded</span><span class=p>[</span><span class=s1>&#39;test&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>y_preds</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>preds_output</span><span class=o>.</span><span class=n>predictions</span><span class=p>,</span> <span class=n>axis</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>y_true</span> <span class=o>=</span> <span class=n>emotions_encoded</span><span class=p>[</span><span class=s1>&#39;validation&#39;</span><span class=p>][</span><span class=s1>&#39;label&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># for classification</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>plot_confusion_matrix</span><span class=p>(</span><span class=n>y_preds</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=n>labels</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>cm</span> <span class=o>=</span> <span class=n>confusion_matrix</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_preds</span><span class=p>,</span> <span class=n>normalize</span><span class=o>=</span><span class=s2>&#34;true&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>4</span><span class=p>,</span> <span class=mi>4</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>disp</span> <span class=o>=</span> <span class=n>ConfusionMatrixDisplay</span><span class=p>(</span><span class=n>confusion_matrix</span><span class=o>=</span><span class=n>cm</span><span class=p>,</span> <span class=n>display_labels</span><span class=o>=</span><span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>disp</span><span class=o>.</span><span class=n>plot</span><span class=p>(</span><span class=n>cmap</span><span class=o>=</span><span class=s2>&#34;Blues&#34;</span><span class=p>,</span> <span class=n>values_format</span><span class=o>=</span><span class=s2>&#34;.2f&#34;</span><span class=p>,</span> <span class=n>ax</span><span class=o>=</span><span class=n>ax</span><span class=p>,</span> <span class=n>colorbar</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=s2>&#34;Normalized confusion matrix&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plot_confusion_matrix</span><span class=p>(</span><span class=n>y_preds</span><span class=p>,</span> <span class=n>y_true</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><figure><img src=/p/llm1/img/9.png width='400px"'><figcaption><h4>Confusion Matrix</h4></figcaption></figure><p>å¯ä»¥å†™ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œå°†æµ‹è¯•é›†çš„losså’Œé¢„æµ‹ç»“æœæ˜ å°„åˆ°æµ‹è¯•é›†ä¸­ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.nn.functional</span> <span class=kn>import</span> <span class=n>cross_entropy</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>forward_pass_with_label</span><span class=p>(</span><span class=n>batch</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># Place all input tensors on the same device as the model</span>
</span></span><span class=line><span class=cl>    <span class=n>inputs</span> <span class=o>=</span> <span class=p>{</span><span class=n>k</span><span class=p>:</span><span class=n>v</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span> <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=n>batch</span><span class=o>.</span><span class=n>items</span><span class=p>()</span>
</span></span><span class=line><span class=cl>              <span class=k>if</span> <span class=n>k</span> <span class=ow>in</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>model_input_names</span><span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>pred_label</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>output</span><span class=o>.</span><span class=n>logits</span><span class=p>,</span> <span class=n>axis</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=n>cross_entropy</span><span class=p>(</span><span class=n>output</span><span class=o>.</span><span class=n>logits</span><span class=p>,</span> <span class=n>batch</span><span class=p>[</span><span class=s1>&#39;label&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                             <span class=n>reduction</span><span class=o>=</span><span class=s1>&#39;none&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># Place outputs on CPU for compatibility with other dataset columns</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>{</span><span class=s2>&#34;loss&#34;</span><span class=p>:</span> <span class=n>loss</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;predicted_label&#34;</span><span class=p>:</span> <span class=n>pred_label</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>emotions_encoded</span><span class=p>[</span><span class=s1>&#39;validation&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>emotions_encoded</span><span class=p>[</span><span class=s1>&#39;validation&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>map</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>forward_pass_with_label</span><span class=p>,</span> <span class=n>batched</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>16</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><h4 id=push-into-huggingface>Push into Huggingface</h4><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># åœ¨Jupyter Jotebookä¸­ç™»å½•huggingface</span>
</span></span><span class=line><span class=cl><span class=c1># éœ€è¦åœ¨huggingfaceæ³¨å†Œä¸€ä¸ªwritable token</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>huggingface_hub</span> <span class=kn>import</span> <span class=n>notebook_login</span>
</span></span><span class=line><span class=cl><span class=n>notebook_login</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>trainer</span><span class=o>.</span><span class=n>push_to_hub</span><span class=p>(</span><span class=n>commit_message</span><span class=o>=</span><span class=s2>&#34;Training completed!&#34;</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><figure><img src=/p/llm1/img/7.png width='400px"'><figcaption><h4>Huggingface Login</h4></figcaption></figure><figure><img src=/p/llm1/img/10.png width='600px"'><figcaption><h4>Huggingface Repo Page</h4></figcaption></figure><p>å½“éœ€è¦åœ¨å…¶ä»–åœ°æ–¹è°ƒç”¨è¿™ä¸ªæ¨¡å‹æ—¶ï¼Œå¯ä»¥é€šè¿‡transformersåŒ…çš„<code>pipeline</code>è½»æ¾å®ç°ï¼š</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>pipeline</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model_id</span> <span class=o>=</span> <span class=s2>&#34;KambriKG/bert-distill_emotion_ft_0531&#34;</span>
</span></span><span class=line><span class=cl><span class=n>classifier</span> <span class=o>=</span> <span class=n>pipeline</span><span class=p>(</span><span class=s2>&#34;text-classification&#34;</span><span class=p>,</span> <span class=n>model</span><span class=o>=</span><span class=n>model_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>custom_tweet</span> <span class=o>=</span> <span class=s2>&#34;I saw a movie today and it was really good&#34;</span>
</span></span><span class=line><span class=cl><span class=n>preds</span> <span class=o>=</span> <span class=n>classifier</span><span class=p>(</span><span class=n>custom_tweet</span><span class=p>,</span> <span class=n>return_all_scores</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span></code></pre></td></tr></table></div></div><hr><h2 id=reference>Reference</h2><p><a class=link href=https://arxiv.org/abs/1810.04805 target=_blank rel=noopener>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></p><p><a class=link href=https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertModel target=_blank rel=noopener>Huggingface-BERTæ–‡æ¡£</a></p><p><a class=link href=https://mccormickml.com/2019/07/22/BERT-fine-tuning/ target=_blank rel=noopener>Chris McCormick&rsquo;s Blog</a></p><p><a class=link href=https://zh.d2l.ai/chapter_attention-mechanisms/transformer.html target=_blank rel=noopener>åŠ¨æ‰‹å­¦æ·±åº¦å­¦ä¹ (PyTorch)</a></p><p><a class=link href="https://search.bilibili.com/all?vt=69025821&amp;keyword=%E4%BA%94%E9%81%93%E5%8F%A3%E7%BA%B3%E4%BB%80&amp;from_source=webtop_search&amp;spm_id_from=333.1007&amp;search_source=5" target=_blank rel=noopener>bilibili-äº”é“å£çº³ä»€-BERTã€T5ã€GPTåˆé›†</a></p><blockquote><p>å­¦ä¹ BERTæ—¶åœ¨äº”é“å£çº³ä»€çš„é¢‘é“æ”¶ç›Šè‰¯å¤šï¼Œã€ŠåŠ¨æ‰‹å†™BERTã€‹ç³»åˆ—æ•™ç¨‹éå¸¸é€‚åˆå¯¹LLMæœ‰ä¸€å®šè®¤è¯†ä½†ç¼ºä¹å®è·µç»éªŒçš„å…¥é—¨è€…å­¦ä¹ å‚è€ƒã€‚</p></blockquote></section><footer class=article-footer><section class=article-tags><a href=/tags/%E6%96%87%E6%A1%A3/>æ–‡æ¡£</a>
<a href=/tags/ai-infra/>AI Infra</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentColor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css integrity=sha384-n8MVd4RsNIU0tAv4ct0nTaAbDJwPJzDEaqSD1odI+WdtXRGWt2kTvGFasHpSy3SV crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js integrity=sha384-XjKyOOlGwcjNTAIQHIpgOno0Hl1YQqzUOEleOLALmuqehneUG+vnGctmUb0ZY0l8 crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{const e=document.querySelector(".main-article");renderMathInElement(e,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>ç›¸å…³æ–‡ç« </h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/p/llm3/><div class=article-image><img src=/p/llm3/img/cover.1e2c906a89d3e1641161237e9d228d85_hu_c2dccf53b54c7c8f.jpg width=250 height=150 loading=lazy alt="Featured image of post Infraå…¥é—¨â€”â€”An Overview of AI Infra" data-key=llm3 data-hash="md5-HiyQaonT4WQRYSN+nSKNhQ=="></div><div class=article-details><h2 class=article-title>Infraå…¥é—¨â€”â€”An Overview of AI Infra</h2></div></a></article><article class=has-image><a href=/p/llm2/><div class=article-image><img src=/p/llm2/img/cover.54ae66259e3c1b9a27ec946b3bb120cb_hu_253e638abf5259b5.png width=250 height=150 loading=lazy alt="Featured image of post æ‰‹æ“Transformerï¼šæ·±å…¥æ¶æ„ç»†èŠ‚" data-key=llm2 data-hash="md5-VK5mJZ48G5on7JRrO7Egyw=="></div><div class=article-details><h2 class=article-title>æ‰‹æ“Transformerï¼šæ·±å…¥æ¶æ„ç»†èŠ‚</h2></div></a></article><article class=has-image><a href=/p/triton1/><div class=article-image><img src=/p/triton1/img/cover.67e39d5f04b0c7d5d295130692a51159_hu_f4abc157212c5d24.jpg width=250 height=150 loading=lazy alt="Featured image of post Tritonå­¦ä¹ â€”â€”Vector Addition, Fused Softmax, Matrix Multiplication" data-key=Triton1 data-hash="md5-Z+OdXwSwx9XSlRMGkqURWQ=="></div><div class=article-details><h2 class=article-title>Tritonå­¦ä¹ â€”â€”Vector Addition, Fused Softmax, Matrix Multiplication</h2></div></a></article><article class=has-image><a href=/p/hpc1/><div class=article-image><img src=/p/hpc1/img/cover.71e6162ba557f0a391bc5e9e5533f13f_hu_ea8068ab11796830.png width=250 height=150 loading=lazy alt="Featured image of post å¹¶å‘ç¯å¢ƒä¸‹çš„é˜Ÿåˆ—ä¼˜åŒ–â€”â€”æ— é”é˜Ÿåˆ—" data-key=hpc1 data-hash="md5-ceYWK6VX8KORvF6eVTPxPw=="></div><div class=article-details><h2 class=article-title>å¹¶å‘ç¯å¢ƒä¸‹çš„é˜Ÿåˆ—ä¼˜åŒ–â€”â€”æ— é”é˜Ÿåˆ—</h2></div></a></article><article class=has-image><a href=/p/hello-world/><div class=article-image><img src=/p/hello-world/img/cover.875f03a2ec7ba6cf35d6c32b0e811dab_hu_92077aa9cb038470.jpg width=250 height=150 loading=lazy alt="Featured image of post Hello World" data-key=hello-world data-hash="md5-h18Doux7ps811sMrDoEdqw=="></div><div class=article-details><h2 class=article-title>Hello World</h2></div></a></article></div></div></aside><script src=https://utteranc.es/client.js repo=KaigeZheng/KaigeZheng.github.io issue-term=pathname crossorigin=anonymous async></script><style>.utterances{max-width:unset}</style><script>let utterancesLoaded=!1;function setUtterancesTheme(e){let t=document.querySelector(".utterances iframe");t&&t.contentWindow.postMessage({type:"set-theme",theme:`github-${e}`},"https://utteranc.es")}addEventListener("message",e=>{if(e.origin!=="https://utteranc.es")return;utterancesLoaded=!0,setUtterancesTheme(document.documentElement.dataset.scheme)}),window.addEventListener("onColorSchemeChange",e=>{if(!utterancesLoaded)return;setUtterancesTheme(e.detail)})</script><footer class=site-footer><section class=copyright>&copy;
2024 -
2025 Kambri's Blog</section><section class=powerby>ä½¿ç”¨ <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a> æ„å»º<br>ä¸»é¢˜ <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.30.0>Stack</a></b> ç”± <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a> è®¾è®¡</section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.c922af694cc257bf1ecc41c0dd7b0430f9114ec280ccf67cd2c6ad55f5316c4e.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>